{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L1urWdgGYfsK"
      },
      "source": [
        "\n",
        "Sources:\n",
        "\n",
        "https://www.kaggle.com/code/barankutluay/heart-failure-prediction-dataset \n",
        "\n",
        "https://towardsdatascience.com/building-a-machine-learning-pipeline-3bba20c2352b\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "7KfZ3iYcnCRM",
        "outputId": "79fe4390-2fbe-4a6f-feaa-cbb49965f0bc"
      },
      "outputs": [],
      "source": [
        "! pip install matplotlib==3.4.2  # Using version 3.4.2 of matplotlib for some of the specific matplotlib functions that I use\n",
        "# You will need to restart your runtime after this step."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf0VxFTsiRl6"
      },
      "source": [
        "# Get Dataset from Kaggle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUih9ujXfSLJ",
        "outputId": "03246c50-3ba6-4fa3-ac55-fa4e587a0a8e"
      },
      "outputs": [],
      "source": [
        "# Importing my dataset from Kaggle to make it easily accessible to Google Colab\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "# To get the API quote from your kaggle, go to kaggle and sign in.\n",
        "# On the top right, select your profile picture, and click the 'Account' tab.\n",
        "# Scroll down to the 'API' section under the 'Account' tab, and select 'Create New API Token'\n",
        "# This should download a 'kaggle.json' file on to your computer. Open that file on notepad, and copy the entire file. \n",
        "# Paste the text you copied into the string in the echo command below (at which point you will un-comment / remove the three hashtags) from that command.  \n",
        "\n",
        "### ! echo 'ENTER YOUR OWN API TOKEN HERE' > kaggle.json\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d fedesoriano/heart-failure-prediction\n",
        "! unzip heart-failure-prediction.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hoggWlY-KFrG",
        "outputId": "e580e53f-3f16-47aa-ad3a-e24e8f910002"
      },
      "outputs": [],
      "source": [
        "# Importing my dataset from Kaggle to make it easily accessible to Google Colab\n",
        "\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "# To get the API quote from your kaggle, go to kaggle and sign in.\n",
        "# On the top right, select your profile picture, and click the 'Account' tab.\n",
        "# Scroll down to the 'API' section under the 'Account' tab, and select 'Create New API Token'\n",
        "# This should download a 'kaggle.json' file on to your computer. Open that file on notepad, and copy the entire file. \n",
        "# Paste the text you copied into the string in the echo command below (at which point you will un-comment / remove the hashtag) from that command.  \n",
        "\n",
        "! echo '{\"username\":\"joweriaekram\",\"key\":\"7793b94a4cac14f03280db86a63b72b8\"}' > kaggle.json\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! kaggle datasets download -d fedesoriano/heart-failure-prediction\n",
        "! unzip heart-failure-prediction.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ch3SstxaiXCQ"
      },
      "source": [
        "# Importing Libraries and Understanding the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.273912Z",
          "iopub.status.busy": "2022-10-18T16:13:34.273571Z",
          "iopub.status.idle": "2022-10-18T16:13:34.286201Z",
          "shell.execute_reply": "2022-10-18T16:13:34.285051Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.273881Z"
        },
        "id": "E3qjjGpCXy19",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Import the required libraries\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "# Set sns theme to your preferred color palette\n",
        "#sns.set_theme(palette = \"mako\")\n",
        "\n",
        "data = pd.read_csv('heart.csv')  # read csv file\n",
        "df = data.copy()  # create a copy to use for future reference, so I have a copy of my original dataset when needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.320574Z",
          "iopub.status.busy": "2022-10-18T16:13:34.320171Z",
          "iopub.status.idle": "2022-10-18T16:13:34.337224Z",
          "shell.execute_reply": "2022-10-18T16:13:34.336046Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.320544Z"
        },
        "id": "5mWfbPxoXy2E",
        "outputId": "9f71fe81-4c34-4aa1-c927-0a4c314bd056",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.head()  # Visualize the dataset to see what your data entails through the first 5 rows\n",
        "# Numerical Columns:\n",
        "#   Age (years)\n",
        "#   RestingBP (mmHg)\n",
        "#   Cholestrol (mm/dl)\n",
        "#   MaxHR (between 60 - 202)\n",
        "#   Oldpeak (ST, numeric value measured in depression)\n",
        "\n",
        "# Categorical Columns:\n",
        "#   Sex (M/F)\n",
        "#   ChestPainType \n",
        "#     (TA: Typical Angina, ATA: Atypical Angina, \n",
        "#      NAP: Non-Anginal Pain, ASY: Asymptomatic)\n",
        "#   FastingBS (0/1) - 1 indicating if FastingBS > 120 mg/dl\n",
        "#   RestingECG (Normal, ST:ST-T wave abnormality, LVH: left ventricular hypertrophy)\n",
        "#   ExerciseAngina (Y/N)\n",
        "#   ST_Slope (Up, Flat, Down)\n",
        "#   HeartDisease (0/1) - 1 indicating heart disease\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.361365Z",
          "iopub.status.busy": "2022-10-18T16:13:34.361035Z",
          "iopub.status.idle": "2022-10-18T16:13:34.373214Z",
          "shell.execute_reply": "2022-10-18T16:13:34.37187Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.361335Z"
        },
        "id": "g896S41eXy2F",
        "outputId": "4fa494f9-2c88-4e42-d036-fd7fead8a4af",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.shape  # Will return the number of rows and columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.375174Z",
          "iopub.status.busy": "2022-10-18T16:13:34.37481Z",
          "iopub.status.idle": "2022-10-18T16:13:34.392247Z",
          "shell.execute_reply": "2022-10-18T16:13:34.39108Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.375141Z"
        },
        "id": "MNhP97yYXy2G",
        "outputId": "a206118a-be8e-43d2-ae53-241e869c667b",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.info()  # Will inform you of the datatype of each variable, as well as if there are any null or missing values in each column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.394094Z",
          "iopub.status.busy": "2022-10-18T16:13:34.39372Z",
          "iopub.status.idle": "2022-10-18T16:13:34.433154Z",
          "shell.execute_reply": "2022-10-18T16:13:34.431948Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.394061Z"
        },
        "id": "zemmRW3ZXy2H",
        "outputId": "5c527e70-0420-44b1-bea8-1f0226b479b9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.describe().T # Describe the data-frame (transposed) - defaults to describing only numerical\n",
        "# If you want to describe all, run the following command:\n",
        "# df.describe(include = \"all\").T\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2022-10-18T16:13:34.468172Z",
          "iopub.status.busy": "2022-10-18T16:13:34.46772Z",
          "iopub.status.idle": "2022-10-18T16:13:34.478039Z",
          "shell.execute_reply": "2022-10-18T16:13:34.477048Z",
          "shell.execute_reply.started": "2022-10-18T16:13:34.468139Z"
        },
        "id": "wQKogxAAXy2K",
        "outputId": "fd0bd382-acca-4b63-c449-21adfa3e652f",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "df.isnull().sum()  # Checking for null values\n",
        "# In this case there are no null values. If there are some, you can use a heatmap to visualize them if you want."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CP-82d38ij0Y"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkiMo-RIMbZE",
        "outputId": "e6be46ee-7a3c-4866-ecbe-97e107d0ea82"
      },
      "outputs": [],
      "source": [
        "# Represent categorical data in numbers \n",
        "# Ex: the ST_Slope variable has 'Up', 'Flat', and 'Down' as it's values. \n",
        "# These will be represented by 0, 1, 2\n",
        "\n",
        "from pandas.core.arrays import categorical \n",
        "\n",
        "# These are the variables I classified as categorical/binary that needed to be coded\n",
        "\n",
        "categorical_data = [\"Sex\",\"ChestPainType\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\"]\n",
        "\n",
        "codes = {}  # Create a dictionary to store the codes of the conversion\n",
        "for i in df:  # For each variable in the data frame \n",
        "  if i in categorical_data:  # For each variable that was classified as categorical\n",
        "    specific_codes = {}  # Create a dictionary for that variable's code conversion \n",
        "    df[i] = df[i].astype(\"category\")  # Convert that variable from 'object' datatype to category\n",
        "    df[i] = df[i].cat.codes  # Create codes for the categories and replace in the dataset \n",
        "    coded = df[i].unique()  # Get the unique values (the codes) from the variable\n",
        "    count = 0  # Count initialized. Later used for accessing specific indexes\n",
        "    for j in data[i].unique():  # For each unique value\n",
        "      specific_codes[j] = coded[count]  # Create an item in the dictionary with the value, and tell it which code correlates\n",
        "      count += 1  # Count incremented\n",
        "    codes[i] = specific_codes  # Create a new item in the overall dictionary with the dictionary created for this specific variable's codes\n",
        "\n",
        "\n",
        "# View our created dictionary:\n",
        "for i in codes:\n",
        "  print(\"{} -\".format(i))\n",
        "  for j in codes[i]:\n",
        "    print(\"{}: {}\".format(j, codes[i][j]))\n",
        "  print()\n",
        "\n",
        "# These are the variables I classified as categorical/binary\n",
        "categorical_data = [\"Sex\",\"ChestPainType\",\"FastingBS\",\"RestingECG\",\"ExerciseAngina\",\"ST_Slope\",\"HeartDisease\"]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "M3GaOUfwQico",
        "outputId": "cd01af91-b598-44a9-fd7c-59f1d132258f"
      },
      "outputs": [],
      "source": [
        "# Revisualize the now coded dataset\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "id": "dka71sZACJV5",
        "outputId": "dd4bc07d-ed8c-416c-9dba-dd2f07ec297f"
      },
      "outputs": [],
      "source": [
        "# Revisualize the now coded dataset\n",
        "df.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnJizAmBipAQ"
      },
      "source": [
        "# Understanding Variable Correlations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usCNV9drNNfv",
        "outputId": "6b03914e-7a5a-441b-c4dd-c42676fa3740"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "\n",
        "fs_data = df.copy() # copy of dataset for feature selection\n",
        "x = fs_data.iloc[:, 0:11]  # independent variables\n",
        "y = fs_data.iloc[:, -1]    # target column / what we're trying to predict\n",
        "\n",
        "# Transforming Old Peak to be positive by shifting it by 2.6 \n",
        "x['Oldpeak'] = [i + 2.6 for i in x['Oldpeak']]\n",
        "\n",
        "# Using SciKit Learn's Feature Selection \n",
        "bf = SelectKBest(score_func=chi2, k='all')\n",
        "fit = bf.fit(x, y)\n",
        "\n",
        "\n",
        "# Creating a vertical pandas data frame with the scores and variable names\n",
        "fs_scores = pd.DataFrame(fit.scores_)\n",
        "fs_cols = pd.DataFrame(x.columns)\n",
        "featured = pd.concat([fs_cols, fs_scores], axis = 1)\n",
        "\n",
        "# Giving the Columns appropriate titles\n",
        "featured.columns = ['Variable', 'Scores']\n",
        "\n",
        "# Sorting by descending order\n",
        "total = len(featured['Variable'])\n",
        "print(featured.nlargest(total, 'Scores'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 599
        },
        "id": "2Uq2V-OnSOuB",
        "outputId": "de709187-0a41-4a4a-f2da-c2402e82a0f1"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "import warnings\n",
        "\n",
        "# Model Extra Tree Classifier - to learn more about it: https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html\n",
        "model = ExtraTreesClassifier()\n",
        "model.fit(x, y)\n",
        "\n",
        "# Create a pandas series of the feature importance, and sorted in descending order\n",
        "imp = pd.Series(model.feature_importances_, index = x.columns)\n",
        "sorted = imp.nlargest(total)\n",
        "\n",
        "with warnings.catch_warnings():  # There was a function I used here that matplotlib did not appreciate, \n",
        "  warnings.simplefilter(\"ignore\")  # so I ignored the warnings. You don't have to worry about that though.\n",
        "\n",
        "  fig, ax = plt.subplots(figsize=(10, 10))  # Creates the general image size, empty plot\n",
        "  plt.xticks(fontsize = 15)  # controls the labels on the x axis\n",
        "  bars= ax.barh(sorted.index, sorted.values)  # Creates the horizontal bar graph based on the data\n",
        "  ax.set_yticklabels(sorted.index, fontsize = 15)  #controls the labels on the y axis\n",
        "  ax.bar_label(bars, fmt='%.3f', fontsize = 15, padding = 10)  # Labels the exact value of each variable on the bar graph\n",
        "  ax.set_xlim(right=0.250)  # Extends the right x limit to inlcude 0.250 so the bar for ST_Slope isn't cut off\n",
        "\n",
        "\n",
        "plt.show()  # Shows the graph created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "JCyh16j7iDlh",
        "outputId": "927cbeb6-78ce-4b5c-d232-52cb72860050"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10))  # Creates the general figure with the specified size\n",
        "\n",
        "# Uses sns aesthetics to create a heatmap using the .corr function, annotated to include the values, formatted to the second decimal point\n",
        "sns.heatmap(df.corr(), annot=True,fmt='.2f');  # The .corr function finds the correlations between ALL the variables in a dataframe\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "Vg1DhWuKhyaI",
        "outputId": "c6731690-92cc-469b-eeb4-91ad1404206f"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,10)) # Creates the general figure with the specified size\n",
        "mask = np.triu(df.corr()) # Keeps only the upper triangle, as the lower triangle had repetitive information\n",
        "\n",
        "# Uses sns aesthetics to create a heatmap using the .corr function, annotated to include the values, formatted to the second decimal point\n",
        "sns.heatmap(df.corr(), mask=mask, annot=True,fmt='.2f');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "id": "rQRn1VR6foNR",
        "outputId": "143b30fb-b409-4a28-d47c-a7b55c2448bb"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(style=\"white\")  # Set the theme to white to change the aesthetic of this plot as an example.\n",
        "\n",
        "plt.figure(figsize=(10,10)) # Creates the general figure with the specified size\n",
        "mask = np.triu(df.corr()) # Keeps only the upper triangle, as the lower triangle had repetitive information\n",
        "\n",
        "# Uses sns aesthetics to create a heatmap using the .corr function, no annotations, chose the color palette to be blues\n",
        "# Changed specifc display features such as line width and the color bar size\n",
        "\n",
        "sns.heatmap(df.corr(), mask=mask, square=True, annot=False, cmap=sns.color_palette(\"Blues\"), linewidths=3, cbar_kws={\"shrink\": .5});"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ja0ffmE-mDGc"
      },
      "source": [
        "# Data Analysis and Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBFpkSCxmV2Z"
      },
      "source": [
        "## Individual Variables Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "9_STl9FDi3e4",
        "outputId": "48235e76-07cc-4b21-b415-4c7d1d5dd890"
      },
      "outputs": [],
      "source": [
        "sns.set_theme(palette = \"mako\", style=\"darkgrid\")  # Setting sns theme to mako (just an aesthetic choice)\n",
        "df2 = data.copy()  # Copying the data so I don't change the original dataset\n",
        "\n",
        "f_hd = ((df2['Sex']==\"F\") & (df2['HeartDisease']==1)).sum()  # Counting how many rows were both female and positive for heart disease\n",
        "f = (df2['Sex']==\"F\").sum()  # Counting how many rows were female\n",
        "c_fhd = (f_hd/f) * 100  # Calculating the percentage of females with heart disease compared to the overall female population in the dataset\n",
        "\n",
        "m_hd = ((df2['Sex']==\"M\") & (df2['HeartDisease']==1)).sum()  # Counting how many rows were both male and positive for heart disease\n",
        "m = (df2['Sex']==\"M\").sum()  # Counting how many rows were male\n",
        "c_mhd = (m_hd/m) * 100  # Calculating the percentage of females with heart disease compared to the overall female population in the dataset\n",
        "\n",
        "# Printing the calculation to the second decimal point.\n",
        "print(\"In this dataset, {:.2f}% of women had heart disease, as compared to {:.2f}% of the men.\".format(c_fhd, c_mhd))  \n",
        "\n",
        "\n",
        "df2.HeartDisease = df2.HeartDisease.map({1:\"Heart Disease\", 0:\"No Heart Disease\"})  # mapping the Heart Disease code back\n",
        "sns.countplot(data=df2, x='Sex',hue='HeartDisease')  # Using the countplot to separate based on Heart Disease\n",
        "plt.title(\"Sex vs. Heart Disease\", fontsize= 15);  # Sets the title \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "M6WFb989qwrr",
        "outputId": "e4594af7-2d7b-48b5-b723-5c0207ecfb06"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, balanced_accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "\n",
        "fs_data = df.copy()\n",
        "x = fs_data.iloc[:, 0:11]  # independent variables\n",
        "y = fs_data.iloc[:, -1]    # target column / what we're trying to predict\n",
        "\n",
        "\n",
        "x_training, x_testing, y_training, y_testing = train_test_split(x, y, test_size = 0.2, random_state = 1) # splitting up dataset to training and testing\n",
        "\n",
        "print(x_training.shape, y_training.shape)\n",
        "print(x_testing.shape, y_testing.shape)\n",
        "print(\"###############################################3\")\n",
        "\n",
        "sns.displot(x_training); # View training dataset\n",
        "plt.title(\"X-Training Dataset Transformed\");\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "sns.displot(x_testing); # View testing dataset\n",
        "plt.title(\"X-Testing Dataset Transformed\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "\n",
        "scl = RobustScaler() # Preprocess numerical data \n",
        "x_training = scl.fit_transform(x_training) \n",
        "x_testing = scl.transform(x_testing)\n",
        "\n",
        "sns.displot(x_training); # View data after preprocessing\n",
        "plt.title(\"X-Training Dataset Transformed\");\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "sns.displot(x_testing); # View data after preprocessing\n",
        "plt.title(\"X-Testing Dataset Transformed\")\n",
        "plt.show()\n",
        "print()\n",
        "\n",
        "\n",
        "model = LogisticRegression(class_weight = 'balanced', solver = 'lbfgs', random_state=1) # Model chosen for machine learning\n",
        "lgfit = model.fit(x_training, y_training)\n",
        "\n",
        "hd_pred = model.predict(x_training) # Predicting output using training data\n",
        "\n",
        "cm = confusion_matrix(y_training, hd_pred) # Creating a confusion matrix to compare how the prediction went \n",
        "\n",
        "# Plotting confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.imshow(cm, cmap=\"bone\")\n",
        "\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('No Heart Disease', 'Heart Disease'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('No Heart Disease', 'Heart Disease'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "colors_choose = [\"black\", \"white\", \"white\", \"black\"]\n",
        "c = 0\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color=colors_choose[c])\n",
        "        c+=1\n",
        "plt.show()\n",
        "\n",
        "# Printing the accuracy score for the training dataset \n",
        "\n",
        "print(accuracy_score(y_training, hd_pred)*100)\n",
        "\n",
        "print(balanced_accuracy_score(y_training, hd_pred)*100) # If the dataset might be imbalanced (outliers etc.), you can use a different accuracy method in scikit learn\n",
        "\n",
        "\n",
        "hd_pred_check = model.predict(x_testing) # Prediciting on Testing dataset\n",
        "\n",
        "\n",
        "cm = confusion_matrix(y_testing, hd_pred_check) # Creating a confusion matrix to compare how the prediction went \n",
        "\n",
        "# Plotting confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.imshow(cm, cmap=\"bone\")\n",
        "\n",
        "ax.grid(False)\n",
        "ax.xaxis.set(ticks=(0, 1), ticklabels=('No Heart Disease', 'Heart Disease'))\n",
        "ax.yaxis.set(ticks=(0, 1), ticklabels=('No Heart Disease', 'Heart Disease'))\n",
        "ax.set_ylim(1.5, -0.5)\n",
        "colors_choose = [\"black\", \"white\", \"white\", \"black\"]\n",
        "c = 0\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        ax.text(j, i, cm[i, j], ha='center', va='center', color=colors_choose[c])\n",
        "        c+=1\n",
        "plt.show()\n",
        "\n",
        "# Printing the accuracy score for the testing dataset \n",
        "\n",
        "print(accuracy_score(y_testing, hd_pred_check)*100)\n",
        "print(balanced_accuracy_score(y_testing, hd_pred_check)*100)# If the dataset might be imbalanced (outliers etc.), you can use a different accuracy method in scikit learn\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.6 ('venv')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "d6d70f9a4759b97e421ee54bae746ca0ce0680c376ae7c2657ef0439157da5f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
